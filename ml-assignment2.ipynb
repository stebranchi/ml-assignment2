{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count = dict()\n",
    "train_x = []\n",
    "file = open(\"tweets/tweets-train-data.csv\", \"r\")\n",
    "\n",
    "for line in file:\n",
    "    line_text = line.split(\",\")[0].split()\n",
    "    words = []\n",
    "    for word in line_text:\n",
    "        if word !=\"\":\n",
    "            word = word.lower()\n",
    "            words.append(word)\n",
    "        \n",
    "            try:\n",
    "                token_count[word] += 1\n",
    "            except KeyError:\n",
    "                token_count[word] = 1\n",
    "        \n",
    "    train_x.append(words)\n",
    "\n",
    "file.close()\n",
    "\n",
    "train_y = []\n",
    "file = open(\"tweets/tweets-train-targets.csv\", \"r\")\n",
    "\n",
    "for line in file:\n",
    "    label = line.split()[0]\n",
    "    train_y.append(label)\n",
    "\n",
    "file.close()\n",
    "\n",
    "test_x = []\n",
    "file = open(\"tweets/tweets-test-data.csv\", \"r\")\n",
    "\n",
    "for line in file:\n",
    "    line_txt = line.split(\",\")[0].split()\n",
    "    words = []\n",
    "    for word in line_txt:        \n",
    "        if word !=\"\":\n",
    "            words.append(word.lower())\n",
    "        \n",
    "    test_x.append(words)\n",
    "\n",
    "file.close()\n",
    "\n",
    "test_y = []\n",
    "file = open(\"tweets/tweets-test-targets.csv\", \"r\")\n",
    "\n",
    "for line in file:\n",
    "    test_y.append(line.split()[0])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_list = []\n",
    "for (token, count) in token_count.items():\n",
    "    if count==1:\n",
    "        rare_list.append(token)\n",
    "\n",
    "stop_words = []\n",
    "file = open(\"stop_words.txt\", \"r\")\n",
    "for line in file:\n",
    "    stop_words.append(line.split()[0])\n",
    "file.close()\n",
    "\n",
    "remove = rare_list + stop_words\n",
    "for token in remove:\n",
    "    try:\n",
    "        del token_count[token]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "vocabulary = sorted(token_count.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "n_token = len(token_count)\n",
    "for tweet in train_x:\n",
    "    ft_vector = []\n",
    "    for (k,v) in vocabulary[:100]:\n",
    "        if k in tweet:\n",
    "            ft_vector.append(v/n_token) #token probability\n",
    "        else:\n",
    "            ft_vector.append(0)\n",
    "    train_data.append(ft_vector)\n",
    "\n",
    "train = np.array(train_data)\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for tweet in test_x:\n",
    "    ft_vector = []\n",
    "    for (k,v) in vocabulary[:100]:\n",
    "        if k in tweet:\n",
    "            ft_vector.append(v/n_token)\n",
    "        else:\n",
    "            ft_vector.append(0)\n",
    "    test_data.append(ft_vector)\n",
    "\n",
    "test = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.02, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C=10, kernel='rbf', gamma=0.02)\n",
    "clf.fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          DT       0.59      0.86      0.70       812\n",
      "          HC       0.74      0.40      0.52       799\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      1611\n",
      "   macro avg       0.67      0.63      0.61      1611\n",
      "weighted avg       0.67      0.63      0.61      1611\n",
      "\n",
      "0.6319056486654252\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(test)\n",
    "\n",
    "report = metrics.classification_report(test_y, y_pred)\n",
    "accuracy = metrics.accuracy_score(test_y, y_pred)\n",
    "\n",
    "# the support is the number of instances having the given label in y_test\n",
    "print(report)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "c_values = [0.1, 1, 10, 100, 1000]\n",
    "gamma_values = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "allResults = []\n",
    "\n",
    "for c in c_values:\n",
    "    for gamma in gamma_values:\n",
    "        clf = SVC(C=c, kernel='rbf', gamma=gamma)\n",
    "        \n",
    "        scores = cross_validate(clf, train, train_y, cv=kfold.split(train), \n",
    "                                scoring=['accuracy', 'precision_micro', 'recall_micro', 'f1_micro'], \n",
    "                                n_jobs=-1, return_train_score=False)\n",
    "        \n",
    "        allResults.append((c, gamma, scores['test_accuracy'].mean(), scores['test_precision_micro'].mean(), \n",
    "                   scores['test_recall_micro'].mean(), scores['test_f1_micro'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [accuracy for [C, gamma, accuracy, precision, recall, f1] in allResults]\n",
    "best_index = np.array(accuracies).argmax()\n",
    "\n",
    "best_c = allResults[best_index][0]\n",
    "best_gamma = allResults[best_index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          DT       0.84      0.71      0.77       812\n",
      "          HC       0.75      0.86      0.80       799\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1611\n",
      "   macro avg       0.79      0.79      0.79      1611\n",
      "weighted avg       0.79      0.79      0.79      1611\n",
      "\n",
      "0.7864680322780881\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=best_c, kernel='rbf', gamma=best_gamma)\n",
    "clf.fit(train, train_y)\n",
    "\n",
    "y_pred = clf.predict(test)\n",
    "\n",
    "report = metrics.classification_report(test_y, y_pred)\n",
    "accuracy = metrics.accuracy_score(test_y, y_pred)\n",
    "\n",
    "print (str(report) + \"\\n\" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test_pred.txt\", \"w\")\n",
    "\n",
    "for label in y_pred:\n",
    "    label = label + \"\\n\"\n",
    "    file.write(label)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
